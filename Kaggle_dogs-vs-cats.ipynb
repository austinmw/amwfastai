{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle dogs-vs-cats competition\n",
    "\n",
    "### Easy steps to train a world-class image classifier:\n",
    "1. freeze all but last layer\n",
    "1. turn on caching of frozen layers\n",
    "1. Use `lr_find()` to find highest learning rate where loss is still clearly improving\n",
    "1. Train last layer from precomputed activations for 1-2 epochs\n",
    "1. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "1. Unfreeze all layers\n",
    "1. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "1. Use `lr_find()` again\n",
    "1. Train full network with cycle_mult=2 until over-fitting\n",
    "1. Check validation results, compare to other models\n",
    "1. Select best model, retrain entirely on full data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "import pathlib\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "\n",
    "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i])\n",
    "        \n",
    "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))        \n",
    "\n",
    "\n",
    "def most_by_mask(mask, mult):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct): \n",
    "    mult = -1 if (y==1)==is_correct else 1\n",
    "    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.3.9.1 / client 1.3.10)\n",
      "Downloading sampleSubmission.csv to /home/paperspace/data/kaggle/dogs-vs-cats\n",
      "  0%|                                               | 0.00/86.8k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 86.8k/86.8k [00:00<00:00, 20.3MB/s]\n",
      "Downloading test1.zip to /home/paperspace/data/kaggle/dogs-vs-cats\n",
      " 98%|███████████████████████████████████████▏| 266M/271M [00:03<00:00, 81.0MB/s]\n",
      "100%|████████████████████████████████████████| 271M/271M [00:04<00:00, 70.7MB/s]\n",
      "Downloading train.zip to /home/paperspace/data/kaggle/dogs-vs-cats\n",
      " 84%|█████████████████████████████████▍      | 454M/543M [00:09<00:01, 53.8MB/s]"
     ]
    }
   ],
   "source": [
    "PATH = '/home/paperspace/data/kaggle/dogs-vs-cats/'\n",
    "!mkdir -p {PATH}\n",
    "!kaggle competitions download -c dogs-vs-cats -p {PATH}\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q '{PATH}/*.zip' -d {PATH}\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(PATH,'train')\n",
    "os.listdir(TRAIN_PATH)[:3]\n",
    "all_train = glob(os.path.join(TRAIN_PATH, '*.jpg'))\n",
    "len(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = glob(os.path.join(TRAIN_PATH, 'dog*.jpg'))\n",
    "cats = glob(os.path.join(TRAIN_PATH, 'cat*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_img = plt.imread(dogs[0])\n",
    "plt.imshow(dog_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle training data, move some to validation set, place in folders according to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dogs)\n",
    "np.random.shuffle(cats)\n",
    "\n",
    "VALID_PATH = os.path.join(PATH, 'valid')\n",
    "TRAIN_DOG_PATH = os.path.join(TRAIN_PATH, 'dogs')\n",
    "TRAIN_CAT_PATH = os.path.join(TRAIN_PATH, 'cats')\n",
    "VALID_DOG_PATH = os.path.join(VALID_PATH, 'dogs')\n",
    "VALID_CAT_PATH = os.path.join(VALID_PATH, 'cats')\n",
    "\n",
    "mk_dirs = [VALID_PATH, TRAIN_DOG_PATH, TRAIN_CAT_PATH, VALID_DOG_PATH, VALID_CAT_PATH]\n",
    "for p in mk_dirs:\n",
    "    pathlib.Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "valid_frac = 0.1\n",
    "\n",
    "dogs_move = ([(f, VALID_DOG_PATH) for f in dogs[:int(len(dogs)*valid_frac)]] +\n",
    "             [(f, TRAIN_DOG_PATH) for f in dogs[int(len(dogs)*valid_frac):]])\n",
    "\n",
    "cats_move = ([(f, VALID_CAT_PATH) for f in cats[:int(len(cats)*valid_frac)]] +\n",
    "             [(f, TRAIN_CAT_PATH) for f in cats[int(len(cats)*valid_frac):]])\n",
    "\n",
    "both_move = dogs_move + cats_move\n",
    "\n",
    "# pbar = tqdm(total=len(both_move))\n",
    "def move_file(file_dst_tuple):\n",
    "    try:\n",
    "        shutil.move(file_dst_tuple[0],file_dst_tuple[1])\n",
    "        # pbar.update(1)\n",
    "    except:\n",
    "        print(\"Problem moving %s\" %  file_dst_tuple[0])\n",
    "    \n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "_ = pool.imap_unordered(move_file, both_move)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "!ls {VALID_PATH}\n",
    "!ls {TRAIN_DOG_PATH} | wc -l\n",
    "!ls {TRAIN_CAT_PATH} | wc -l\n",
    "!ls {VALID_DOG_PATH} | wc -l\n",
    "!ls {VALID_CAT_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below if you need to reset your precomputed activations\n",
    "# shutil.rmtree(f'{PATH}tmp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select input image size and architecture, import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "arch=resnet34\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
    "data.val_y\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so $\\text{cat} = 0$, $\\text{dog} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a learning rate\n",
    "Gradually increase learning rate from very small value until loss stops decreasing, in order to find learning rate that improves loss most quickly (lowest slope, and round up, since this will be the MAX rate used after adding additional learning rates later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
    "lrf=learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the learning rate schedule\n",
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the previous plot *iteration* is one iteration (or *minibatch*) of SGD. In one epoch there are \n",
    "(num_train_samples/num_iterations) of SGD.\n",
    "\n",
    "We can see the plot of loss versus learning rate to see where our loss stops decreasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is still clearly improving at lr=1e-2 (0.01), so that's what we use. Note that the optimal learning rate can change as we train the model, so you may want to re-run this function from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data augmentations\n",
    "to reduce overfitting/improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "\n",
    "def get_augs():\n",
    "    data = ImageClassifierData.from_paths(PATH, bs=2, tfms=tfms, num_workers=1)\n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]\n",
    "\n",
    "ims = np.stack([get_augs() for i in range(6)])\n",
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train final layer with caching of frozen layers for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
    "learn.fit(1e-2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check current validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['cats', 'dogs']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ -0.00021,  -8.46211],\n",
       "       [ -0.00012,  -8.99907],\n",
       "       [ -0.0002 ,  -8.52839],\n",
       "       [ -0.00017,  -8.68186],\n",
       "       [ -0.00002, -10.94519],\n",
       "       [ -0.00569,  -5.17175],\n",
       "       [ -0.00008,  -9.4206 ],\n",
       "       [ -0.00001, -11.60038],\n",
       "       [ -0.00003, -10.43032],\n",
       "       [ -0.00005,  -9.8709 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on validation set (in log scale)\n",
    "log_preds = learn.predict()\n",
    "log_preds.shape\n",
    "log_preds[:10]\n",
    "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\n",
    "probs = np.exp(log_preds[:,1])        # pr(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), \"Most correct cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), \"Most correct dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn off caching of frozen layers (to enable data augmentation), add SGDR (cyclic LR schedule), continue training final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute=False\n",
    "# reset lr every epoch, for 3 cycles total\n",
    "learn.fit(1e-2, 3, cycle_len=1)\n",
    "learn.sched.plot_lr()\n",
    "learn.save('224_lastlayer')\n",
    "learn.load('224_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune other layers using differential learning rates and learning rate cycle multipler (to slow down resets as training progresses)\n",
    "\n",
    "Final layer is now fully trained. Other layers have already been trained to recognize imagenet photos (whereas final layers were randomly initialized), so don't want to destroy the carefully tuned weights that are already there. The earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason we will use different learning rates for different layers: the first few layers will be at 1e-4, the middle layers at 1e-3, and our FC layers we'll leave at 1e-2 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck optimal learning rate\n",
    "learn.unfreeze()\n",
    "lrf=learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lr=np.array([1e-4,1e-3,1e-2])\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n",
    "learn.sched.plot_lr()\n",
    "learn.save('224_all')\n",
    "learn.load('224_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: plot above is the final layers. Learning rates of earlier layers are set to fractions of the final layers rates.\n",
    "\n",
    "### Check and analyze results on validation set using test time augmentation\n",
    "Make predictions on a number of randomly augmented versions of validation set, then use the average prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]\n",
    "cm = confusion_matrix(y, preds)\n",
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at pictures again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect dogs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare validation results to other models\n",
    "### If this model is best, retrain on full training set, predict on test set, submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
